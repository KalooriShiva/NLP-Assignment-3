{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T15:54:53.813168Z",
     "iopub.status.busy": "2024-11-22T15:54:53.812914Z",
     "iopub.status.idle": "2024-11-22T15:54:54.551655Z",
     "shell.execute_reply": "2024-11-22T15:54:54.550801Z",
     "shell.execute_reply.started": "2024-11-22T15:54:53.813141Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login('API token here')  # Paste your Hugging Face API token here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T15:55:01.937141Z",
     "iopub.status.busy": "2024-11-22T15:55:01.936483Z",
     "iopub.status.idle": "2024-11-22T15:57:04.441435Z",
     "shell.execute_reply": "2024-11-22T15:57:04.440548Z",
     "shell.execute_reply.started": "2024-11-22T15:55:01.937104Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640e962a592648f29fd93780074c6025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112813255555113, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20241122_155552-s1pqzsmf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/abhyudaya3701-indian-institute-of-technology-gandhinagar/llama3_finetune_sst2/runs/s1pqzsmf' target=\"_blank\">binary_classification</a></strong> to <a href='https://wandb.ai/abhyudaya3701-indian-institute-of-technology-gandhinagar/llama3_finetune_sst2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/abhyudaya3701-indian-institute-of-technology-gandhinagar/llama3_finetune_sst2' target=\"_blank\">https://wandb.ai/abhyudaya3701-indian-institute-of-technology-gandhinagar/llama3_finetune_sst2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/abhyudaya3701-indian-institute-of-technology-gandhinagar/llama3_finetune_sst2/runs/s1pqzsmf' target=\"_blank\">https://wandb.ai/abhyudaya3701-indian-institute-of-technology-gandhinagar/llama3_finetune_sst2/runs/s1pqzsmf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e3fdd1a4e4468b93bf00145efed8a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/35.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c94c6e88244a508ca1a5b61424d38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/3.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4602796ea6b64ae080655f0b2e7f80d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/72.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1930bc6807fd48168d0c4ad8b589a9a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/148k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb3a614c9164ce794fc5e79bbdc60ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e54b45fcfa1458284c6e67a35106ce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09603735fd842d6b2b0f8bc9ffbb4a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0c22535b1c4d9baaa3bc53b6c23205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c131df3ecc422eb0f5e28892543620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325817d3a1e74ac283a0a14b7677f015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f66458269a4961bc0c0ef61e9710de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3386e3c43a546d49a1d59bfee776d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "import wandb\n",
    "\n",
    "# Set Kaggle output directory\n",
    "output_dir = \"/kaggle/working/llama3_finetuned\"\n",
    "\n",
    "# Initialize Weights & Biases\n",
    "wandb.init(project=\"llama3_finetune_sst2\", name=\"binary_classification\")\n",
    "\n",
    "# Load SST2 dataset\n",
    "dataset = load_dataset(\"glue\", \"sst2\")\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_name = \"meta-llama/Llama-3.2-1B\"  # Replace with the exact model name or path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T16:00:40.374462Z",
     "iopub.status.busy": "2024-11-22T16:00:40.373615Z",
     "iopub.status.idle": "2024-11-22T16:00:40.381874Z",
     "shell.execute_reply": "2024-11-22T16:00:40.381199Z",
     "shell.execute_reply.started": "2024-11-22T16:00:40.374427Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1235818496"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T14:16:20.472367Z",
     "iopub.status.busy": "2024-11-20T14:16:20.471551Z",
     "iopub.status.idle": "2024-11-20T14:16:21.038858Z",
     "shell.execute_reply": "2024-11-20T14:16:21.037955Z",
     "shell.execute_reply.started": "2024-11-20T14:16:20.472334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", max_length = 128, truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T18:00:22.848084Z",
     "iopub.status.busy": "2024-11-20T18:00:22.847744Z",
     "iopub.status.idle": "2024-11-20T18:00:22.854993Z",
     "shell.execute_reply": "2024-11-20T18:00:22.854287Z",
     "shell.execute_reply.started": "2024-11-20T18:00:22.848054Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for param in model.base_model.parameters():\n",
    "    param.requires_grad = False  # Freeze transformer layers\n",
    "\n",
    "# Unfreeze the final linear layer (qa_outputs)\n",
    "if hasattr(model, \"qa_outputs\"):\n",
    "    for param in model.qa_outputs.parameters():\n",
    "        param.requires_grad = True  # Unfreeze the final linear layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T14:16:32.063623Z",
     "iopub.status.busy": "2024-11-20T14:16:32.062955Z",
     "iopub.status.idle": "2024-11-20T15:16:46.279616Z",
     "shell.execute_reply": "2024-11-20T15:16:46.278904Z",
     "shell.execute_reply.started": "2024-11-20T14:16:32.063590Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67349' max='67349' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67349/67349 59:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.790600</td>\n",
       "      <td>0.711593</td>\n",
       "      <td>0.707569</td>\n",
       "      <td>0.724919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.025 MB of 0.025 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>â–</td></tr><tr><td>eval/f1</td><td>â–</td></tr><tr><td>eval/loss</td><td>â–</td></tr><tr><td>eval/runtime</td><td>â–</td></tr><tr><td>eval/samples_per_second</td><td>â–</td></tr><tr><td>eval/steps_per_second</td><td>â–</td></tr><tr><td>train/epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>train/global_step</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>train/grad_norm</td><td>â–ˆâ–â–â–ˆâ–â–‚â–‚â–â–†â–†â–â–ˆâ–â–ˆâ–†â–â–†â–…â–ˆâ–â–‚â–„â–ƒâ–â–â–‡â–‚â–ƒâ–â–…â–ˆâ–†â–â–â–â–ˆâ–†â–â–â–</td></tr><tr><td>train/learning_rate</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–</td></tr><tr><td>train/loss</td><td>â–ƒâ–‡â–†â–ˆâ–†â–„â–‡â–ˆâ–ƒâ–†â–†â–ˆâ–â–‚â–„â–„â–†â–„â–ƒâ–„â–…â–‚â–…â–ƒâ–‚â–†â–â–„â–„â–…â–„â–ƒâ–ƒâ–„â–ƒâ–‚â–„â–‚â–„â–ƒ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.70757</td></tr><tr><td>eval/f1</td><td>0.72492</td></tr><tr><td>eval/loss</td><td>0.71159</td></tr><tr><td>eval/runtime</td><td>42.9316</td></tr><tr><td>eval/samples_per_second</td><td>20.311</td></tr><tr><td>eval/steps_per_second</td><td>20.311</td></tr><tr><td>total_flos</td><td>5.033525249939866e+16</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>67349</td></tr><tr><td>train/grad_norm</td><td>125.33658</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7906</td></tr><tr><td>train_loss</td><td>0.91841</td></tr><tr><td>train_runtime</td><td>3596.072</td></tr><tr><td>train_samples_per_second</td><td>18.728</td></tr><tr><td>train_steps_per_second</td><td>18.728</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">binary_classification</strong> at: <a href='https://wandb.ai/abhyudaya3701-indian-institute-of-technology-gandhinagar/llama3_finetune_sst2/runs/65a5yd0g' target=\"_blank\">https://wandb.ai/abhyudaya3701-indian-institute-of-technology-gandhinagar/llama3_finetune_sst2/runs/65a5yd0g</a><br/> View project at: <a href='https://wandb.ai/abhyudaya3701-indian-institute-of-technology-gandhinagar/llama3_finetune_sst2' target=\"_blank\">https://wandb.ai/abhyudaya3701-indian-institute-of-technology-gandhinagar/llama3_finetune_sst2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241120_141601-65a5yd0g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=10,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    push_to_hub=False,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "# Define a compute_metrics function\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), axis=1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average=\"binary\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the final model and tokenizer\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Finalize Weights & Biases\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T17:57:54.735291Z",
     "iopub.status.busy": "2024-11-20T17:57:54.734449Z",
     "iopub.status.idle": "2024-11-20T17:57:54.742114Z",
     "shell.execute_reply": "2024-11-20T17:57:54.741287Z",
     "shell.execute_reply.started": "2024-11-20T17:57:54.735242Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1235818496"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T18:00:35.234717Z",
     "iopub.status.busy": "2024-11-20T18:00:35.234358Z",
     "iopub.status.idle": "2024-11-20T18:00:35.243886Z",
     "shell.execute_reply": "2024-11-20T18:00:35.242870Z",
     "shell.execute_reply.started": "2024-11-20T18:00:35.234688Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predictions = trainer.predict(dataset['validation'])\n",
    "model_pred = [np.argmax(x) for x in predictions[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T17:24:23.112557Z",
     "iopub.status.busy": "2024-11-20T17:24:23.111846Z",
     "iopub.status.idle": "2024-11-20T17:24:23.127716Z",
     "shell.execute_reply": "2024-11-20T17:24:23.126874Z",
     "shell.execute_reply.started": "2024-11-20T17:24:23.112525Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0    0.70045   0.71991   0.71005       432\n",
      "     Class 1    0.71729   0.69773   0.70737       440\n",
      "\n",
      "    accuracy                        0.70872       872\n",
      "   macro avg    0.70887   0.70882   0.70871       872\n",
      "weighted avg    0.70895   0.70872   0.70870       872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(dataset['validation']['label']), model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T18:10:35.314026Z",
     "iopub.status.busy": "2024-11-20T18:10:35.313060Z",
     "iopub.status.idle": "2024-11-20T18:13:29.056280Z",
     "shell.execute_reply": "2024-11-20T18:13:29.055565Z",
     "shell.execute_reply.started": "2024-11-20T18:10:35.313990Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a94ec4fea3a48e99eafa40d8f40aa55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53e7797d7d4413e83e02c79bdca8711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/abhyudaya-nair/tokenizer/commit/4c5adcce5d43a5fa7a939ac491d47add1f67ad06', commit_message='Upload tokenizer', commit_description='', oid='4c5adcce5d43a5fa7a939ac491d47add1f67ad06', pr_url=None, repo_url=RepoUrl('https://huggingface.co/abhyudaya-nair/tokenizer', endpoint='https://huggingface.co', repo_type='model', repo_id='abhyudaya-nair/tokenizer'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "\n",
    "model.push_to_hub(\"llama_3.2_fine_tuning\")\n",
    "tokenizer.push_to_hub(\"tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6128283,
     "sourceId": 9962716,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30788,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
